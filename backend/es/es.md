# ElasticSearch 读书笔记

## 0). 基本概念
###  集群（Cluster）
如下图，由多个协同工作的 ES 实例组合成的集合称为集群，图中节点 Node1、Node2、Node3 分别运行了一个 ES 实例，它们组成一个集群。分布式的 ES 集群可以存储海量的数据，也可以从容地面对更高的并发量。

集群也是一种提供无间断服务的方案，得益于分布式系统的架构设计，使得 ES 拥有高可用性和可扩展性。

高可用性，分为服务可用性、数据可用性。
+ 服务可用性，在有部分节点挂掉的情况下系统还可以对外提供服务。
+ 数据可用性，部分节点挂掉，并且这些节点的数据无法恢复的情况下，也能保证数据不丢失。
可扩展性，当并发量提升，或者数据量增多的情况下，可以通过增加节点数来解决问题。

### 节点（Node）
单个 ES 的服务实例叫做节点，本质上就是一个 Java 进程啦。每个实例都有自己的名字。为了标识每个节点，每个节点启动后都会分配一个 UID，存储在 data 目录。各个节点受到集群的管理，我们可以通过增加或者减少节点来达到扩容或减容的目的。

集群里的节点是有分类的，就好像一家公司的不同部门，负责不同的业务和工作，主要的节点类型如下
+ 主节点（Master）。主节点在整个集群是唯一的，Master 从有资格进行选举的节点（Master Eligible）中选举出来。主节点主要负责管理集群变更、元数据的更改。如果要类比的话，主节点像是公司的总经办。
+ 数据节点（Data Node）。其负责保存数据，要扩充存储时候需要扩展这类节点。数据节点还负责执行数据相关的操作，如：搜索、聚合、CURD 等。所以对节点机器的 CPU、内存、I/O 要求都比较高。
+ 协调节点（Coordinating Node）。负责接受客户端的请求，将请求路由到对应的节点进行处理，并且把最终结果汇总到一起返回给客户端。因为需要处理结果集和对其进行排序，需要较高的 CPU 和内存资源。
+ 预处理节点（Ingest Node）。预处理操作允许在写入文档前通过定义好的一些 processors（处理器）和管道对数据进行转换。默认情况下节点启动后就是预处理节点。
+ 部落节点（Tribe Node）。部落节点可以连接到不同集群，并且支持将这些集群当成一个单独的集群处理。但它在未来的版本中将会被淘汰。
+ Hot & Warm Node。不同硬件配置的 Data Node，用来实现 Hot & Warm 架构的节点，有利于降低集群部署成本。例如，在硬件资源好的机器中部署 Hot 类型的数据节点，而在硬件资源一般的机器上部署 Warm Node 节点。

在生产环境中建议将每个节点设置为单一角色。如果业务量或者并发量不大的情况下，为了节省成本可以调整为一个节点多种角色的集群。在开发环境中的话，为了节省资源，一个节点可以设置多种角色（上一章的伪集群模式就很适合）。

> 其实每个节点本身就是一个协调节点

### 分片（Shard）
分片的概念其实很好理解，试想一下如果家里的书多到一个箱子装不下，是不是要找另外一个箱子来装？这些书就好比海量的数据，一台机器存不下，就放到多台机器来存储。

一般来说，面对海量数据的时候，分布式系统可以通过增加机器数量来进行水平扩展。所以，系统需要将数据分成多个小块数据，并且尽量均匀地分配到各个机器上，然后可以通过某种策略找到对应数据块所在的位置。**分片（Shard）是 ES 底层基本的读写单元，分片是为了分割巨大的索引数据，让读写可以由多台机器来完成，从而提高系统的吞吐量。**

### 副本（Replica）
为了保证数据可靠性，一般分布式系统都会对数据进行冗余备份，这个备份也就是副本了。ES将数据副本分为主从两类型：主分片（primary shard）和副分片（replica shard） 。在写入的过程中，先写主分片，成功后并发写副分片，在数据恢复时以主分片为主。多个副本除了可以保证数据可靠性外，还有一个好处是可以承担系统的读负载。

### 集群健康状态
通过集群的健康状态，我们可以了解集群是不是出现问题了。 集群健康状态有以下 3 种。
+ Green，集群处于健康状态，所有的主分片和副本分片都正常运行。
+ Yellow，所有的主分片都运行正常，但是有部分副本分片不正常，意味着存在单点故障的风险（部分主分片没有备份了，一旦这个主分片数据丢失，将导致这些数据永久丢失）。
+ Red，有部分主分片没有正常运行。

需要注意的是，每个索引也有这三种状态，如果索引丢失了一个副本分片，那么这个索引和集群的状态都变为 Yellow 状态，但是其他索引的的状态仍为 Green。

### 索引（Index）
索引是一类相似文档的集合。ES 将数据存储在一个或者多个 Index 中，例如将用户数据存储在 User Index 中，而将订单数据存储在 Order Index 中。一个索引有一个或者多个分片，索引的数据会以某种方式分散到各个分片上去存储。

### Mapping
Mapping 定义了索引里的文档到底有哪些字段及这些字段的类型，类似于数据库中表结构的定义。Mapping 有两种作用：

1. 定义了索引中各个字段的名称和对应的类型；
2. 定义各个字段、倒排索引的相关设置，如使用什么分词器等。

例如，我们在上面定义的 books 索引，其有一个 keyword 类型的字段，名字为 book_id，另外一个字段为 name，其类型为 text。

需要注意的是，Mapping 一旦定义后，已经定义的字段的类型是不能更改的。至于其原因，我们后续的内容会提到。

### 文档（Doc）
我们向 ES 中写入的每一条数据都是一个文档（类似数据库中的一条记录），并且我们搜索也是以文档为单位的，所以文档是 ES 中的主要实体。ES 是面向文档的并且以文档为单位进行搜索的，如一条书本记录。

文档以 JSON 格式进行序列化存储。

每个文档都有唯一的 ID。如果使用：POST /books/_doc 这样插入，ES 会自动生成唯一 ID，也可以使用 POST /books/_doc/1 指定记录的 ID。不指定 ID 时插入的性能会好点，因为系统不需要进一步判断这个 ID 是否已经存在

### 字段（Field）
每个文档都有一个或者多个字段，例如 books 索引指定了书本的记录有 book_id 和 name 两个字段，这些字段都有指定的类型。其实就是 JSON 中的 Key 嘛。

### 词项（Term）
将全文本的内容进行分词后得到的词语就是词项了。例如 "Programmers Love Cat" 使用标准分词器分词后得到 [programmer, love, cat] 这 3 个词项。需要注意的是：分词器除了进行分词外还会进行大小写转换等其他操作。

### 倒排索引与正排索引
将保存实体 ID 到实体数据关联关系的数据结构叫做正排索引，我们熟知的 MySQL InnoDB 的索引就是正排索引，使用的是 B+ 树来实现。

将保存词项到文档实体关联关系的数据结构叫做倒排索引

### 近实时系统
ES 是一个近实时系统，我们写入的数据默认的情况下会在 1 秒后才能被查询到。所以需要注意的是，不能在写入数据成功后，立刻进行查询，这个时候可能会出现查询不到数据或者获取到旧数据的情况。

### Lucene 与 ES 的关系
Lucene 是一个用于全文检索的开源项目，ES 在搜索的底层实现上用的就是 Lucene。你可以简单认为，ES 就是在 Lucene 上增加了分布式特性的系统服务。

Lucene 也有索引，那 Lucene 的索引和 ES 的索引是个怎么样的关系呢？其实 ES 上的分片（Shard）就是一个完整的 Lucene 索引。

## 1). 倒排索引的实现

### 倒排索引的组成部分
倒排索引的实现面临四大难题
1. 分词形成的词项可能是海量的，需要在内存和磁盘高效存储
1. 既然词项是海量的，如何快速找到词项也是一个问题
1. 每个词项对应的文档可能非常多
1. 在词项对应文档多的情况下，多个文档列表做交集的效率是个挑战

在 Lucene 的倒排索引实现中，使用词项索引解决上述 1 和 2 的问题，对于 3 和 4 ，Lucene 对数据进行了压缩处理，使用 Roaring Bitmaps 、 跳表等技术进行快速求交集

倒排索引的组成主要有三大部分
+ Term Index : Term Dictionary 的索引，最好设计得越小越好，这样缓存在内存中也没有压力
+ Term Dictionary : 保存具体的词项
+ Posting List : 保存每个词项对应的文档 ID 列表

相关概念的关系
+ 默认情况下 ES 每秒会把缓存中的数据写入到 Segment ，然后根据某些规则进行刷盘并合并这些 Segment ，所以 Segment 数据一旦写入就不会变，采用不变性设计主要原因，一个是更新数据对磁盘不友好，一个是可变数据会有并发写的问题
+ 逻辑上一个 Segment 上会有多个 Document ，一个 Document 有多个 Field ，这些 Field 的内容会被分词器形成多个 Term ，然后以 Block 的形式保存在 Term Dictionary 中，并且系统会对 Term Dictionary 的内容做索引形成 Term Index 。在搜索时通过 Term Index 找到 Block 后进一步找到 Term 对应的 Posting List 中的文档 ID ，然后计算出符合条件的文档 ID 列表进行返回
+ Segment 中的每个 Field 都有自己的 Term Index 、 Term Dictionary 、 Posting List 结构，也就是说每个 Field 中这些结构都是独立的

### Term Index

[FST](https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/) (Final State Transducers) 类似一种 TRIE 树，是一个有限状态机，具备以下特性
1. 确定 : 任何一个状态，只可能最多有一个转移可以遍历到
1. 无环 : 不可能重复遍历同一个状态
1. transducer : 接收指定的序列，终止于 final 状态，同时会输出一个值

Term Index 使用 FST 实现两个基本功能
1. 快速试错 : 如果在 FST 上不存在，无需遍历整个 Term Dictionary
1. 快速定位到 Block 的位置 : 经过 FST 的输出，可以算出 Block 在文件中的位置

### Posting List 的实现

Posting List 包含的信息比较多，主要分成三个文件存储
1. .doc 文件，记录了文档 ID 信息和 Term 的词频，还额外记录了跳跃表的信息，用来加速文档 ID 的查询，还记录了 Term 在 pos 和 pay 文件中的位置，有助于快速读取
1. .pay 文件，记录 Payload 信息和 Term 在 doc 中的偏移信息
1. .pos 文件，记录了 Term 在 doc 中的位置信息

Posting List 主要面临以下两个问题
1. 如何节省存储 -> 对数据进行压缩存储
1. 如何快速做交集 -> 跳表 、 Roaring Bitmaps 等技术

#### 节省存储 : 整形压缩
整形压缩的核心思想是，用最少的位数表示原数据，并且兼顾数据读取效率
+ PackedBlock : 将 int[] 压缩成为一个 Block ，其压缩方式是把数组中最大的那个数占用的有效位数作为标准，然后各个元素打包的数组中，每个元素都按这个有效位数来算。 PackedBlock 只能存储固定长度的数组数据
+ VIntBlock : 通过使用变长整形编码的方式对数据进行压缩，可以存储复合的数据类型。VInt 采用可变长的字节表示一个整数，每个字节只使用第 1 到第 7 位来存储数据，第 8 位用来作为是否需要读取下一个字节的标记

Lucene 在处理文档的时候，每处理 128 篇文档就会将其对应的文档 ID 数组和词频数组处理为两个 Block : PackedDocDeltaBlock 和 PackedFreqBlock ，并使用 PackedInts 累对数据进行压缩存储，生成一个 PackedBlock 。把最后不足 128 篇文档的数据采用 VIntBlock 存储，并且在生成 PackedBlock 的时候会生成跳表，使得在读取数据时可以快速跳到指定的 PackedBlock

两个正整数的差一定比它们任何一个都要小，利用这个特性可以使需要压缩的数编程更小的数，从而进一步压缩空间

上述过程说白了就是，文档 ID 使用增量编码，数据分块存储，数据按需分配存储空间。这整个过程叫做 FOR (Frame Of Reference)

## 2). 分词器

### 概念
分词是将全文本转换为一系列单词的过程，这些单词称为词项 Term 或者 Token

分词是通过分词器 (Analyzer) 来实现的

除了在数据写入时对数据进行分词，在对全文本进行查询的时候也需要使用相同的分词器对检索内容进行分析

分词器由 3 部分组成
1. Character Filter : 主要对原文本进行格式处理
1. Tokenizer : 按照指定的规则对文本进行切分；负责标记出每个单词的顺序、位置以及单词在原文本中开始和结束的偏移量
1. Token Filter : 对切分后的单词进行处理

## 3). 相关性评分

全文本数据的检索通常没办法用是否相等来得出结果，而是用相关性来决定最后的返回结果

相关性是指搜索内容和结果的相关性，是用来描述文档与查询语句的匹配程度。通过计算相关性，可以得出一个相关性评分，然后根据评分对结果集进行排序，返回最符合的数据给用户。所以打分最终的目标是为了对结果进行排序，找出最匹配的结果集展示给用户

### TF-IDF 算分模型
TF-IDF (Term Frequency-inverse Document Frequency) 是一种关键词统计方法，用来反映一个词在一个文档集合或资料库中的重要程度，其通常用作信息检索、文本挖掘、用户建模的加权因子

如果一个词在一篇文章中出现次数越多，那么这个词对于这篇文章来说就越重要，但同时如果这个词在整个语料库中出现的次数越多，其就不那么重要了。这样做可以提高关键词与文章的相关性，并且减少了常用词对结果的影响

总之，一个词的重要程度跟它在一篇文章中出现的频率成正比，跟它在语料库中出现的频率成反比

+ TF (Term Frequency On Per Document) 表示一个词在一篇文档中出现的频率
$$TF = \frac{词项w在文档中出现的次数}{文档中词项的总数}$$
+ DF (Document Frequency) 表示词项在语料库中出现的频率，如果词项的 DF 越大，表示语料库中包含对应词项的文档就越多，这个词项的重要程度就越低
$$DF = \frac{包含词项w的文档数}{文档总数}$$
+ IDF (Inverse Document Frequency) 表示逆文档频率，其可以通过 DF 计算得到，可简单理解为 DF 的倒数。如果词项的 IDF 越高，说明词项在语料库中越稀有，所以 IDF 代表了词项在语料库中的稀有性
$$IDF = \log \frac{文档总数}{包含词项w的文档数+1}$$

TF-IDF 算分公式

$$TF-IDF(termA) = TF(termA) * IDF(termA)$$

一个词项在一篇文档中出现越多，对于这篇文档越重要，同时词项在整个语料库的稀有性影响着它对某篇文档的重要程度。TF-IDF 本质是对 TF 进行了加权计算，而权重是 IDF

在 ES 5.0 版本后 ES 默认使用了 BM25 (Best Match) 的算分模型，相对 TF-IDF 来说其优化点在于降低 TF 对算分结果的影响力，并且引入了可自定义的参数
+ k1 : 调节词频影响力
+ b : 控制文档篇幅对于得分的影响程度